<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chapter 9: Trainer — babygrad</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div class="container">
    <nav class="sidebar">
      <h2><a href="index.html">babygrad</a></h2>
      <ul>
        <li><a href="index.html">Preface</a></li>
        <li><a href="intro.html">1. Introduction</a></li>
        <li><a href="tensor.html">2. Tensor</a></li>
        <li><a href="autograd.html">3. Automatic Differentiation</a></li>
        <li><a href="nn.html">4. nn</a></li>
        <li><a href="optim.html">5. Optimizer</a></li>
        <li><a href="data.html">6. Data Handling</a></li>
        <li><a href="init.html">7. Initialization</a></li>
        <li><a href="saving.html">8. Model Persistence</a></li>
        <li class="active"><a href="trainer.html">9. Trainer</a></li>
        <li><a href="cnn.html">10. Convolutional NN</a></li>
        <li><a href="solutions.html">11. Solutions</a></li>
        <li><a href="examples.html">12. Examples</a></li>
        <li><a href="conclusion.html">13. Conclusion</a></li>
      </ul>
    </nav>

    <main class="content">
      <h1>Chapter 9: Trainer</h1>

      <p>For any training loop we will write something like this:</p>

      <pre><code>model = Mymodel()
optimizer = myOptimizer()
dataloader = MyDataloader()
for epoch in range(10):
    for batch in dataloader:
        optimizer.zero_grad()
        pred = model(batch.x)
        loss = loss_fn(pred, batch.y)
        loss.backward()
        optimizer.step()</code></pre>

      <p>This works fine, but it becomes repetitive. Every model and every experiment requires writing the same boilerplate. To make our workflow cleaner, we can wrap this logic inside a <strong>Trainer</strong> class.</p>

      <div class="note">
        <p><strong>Note:</strong> This is what our <strong>folder structure</strong> currently looks like. In this chapter, we will work inside <strong>babygrad/trainer.py</strong>.</p>
        <pre><code>project/
├─ .venv/
├─ babygrad/
|   ├─ trainer.py
│   ├─ __init__.py
│   ├─ data.py
│   ├─ init.py
│   ├─ ops.py
│   ├─ tensor.py
│   ├─ nn.py
│   └─ optim.py
├─ examples/
│   └─ simple_mnist.py
└─ tests/</code></pre>
      </div>

      <p>What does the <code>Trainer</code> class need? It needs everything that is used in the training loops.</p>

      <ul>
        <li>Model</li>
        <li>Loss function</li>
        <li>Optimizer</li>
        <li>Dataloader</li>
      </ul>

      <pre><code>trainer=Trainer(model,optimizer,loss_fn,train_loader,val_loader=test_loader)

print("Starting Training...")
trainer.fit(EPOCHS)</code></pre>

      <p><strong>File</strong> : <strong>babygrad/trainer.py</strong></p>

      <div class="exercise">
        <h3>Exercise 9.1</h3>
        <p>Let's write the <strong>fit</strong> method inside the <strong>Trainer</strong> class.</p>
        <pre><code>from babygrad.tensor import Tensor

class Trainer:
    def __init__(self, model, optimizer, loss_fn, train_loader,
                 val_loader=None):
        self.model = model
        self.optimizer = optimizer
        self.loss_fn = loss_fn
        self.train_loader = train_loader
        self.val_loader = val_loader

    def fit(self, epochs: int):
        """
        Runs the training loop for the specified number of epochs.
        """
        for epoch in range(epochs):
            self.model.train() # Set mode to training

            total_loss = 0

            # Your solution here:
            # 1. Iterate over self.train_loader
            # 2. Get batch data (x, y)
            # 3. Zero Gradients
            # 4. Forward Pass
            # 5. Compute Loss
            # 6. Backward Pass
            # 7. Optimizer Step

            print(f"Epoch {epoch+1} Done.")

    def evaluate(self, loader=None):
        """
        Calculates accuracy on the validation set.
        """
        target_loader = loader if loader is not None else self.val_loader
        if target_loader is None:
            return 0.0
        # Hint:
        # 1. Set model to evaluation mode: self.model.eval()
        # 2. Loop over self.val_loader
        # 3. Forward pass only (no backward)
        # 4. Compare predictions to true labels (use argmax(axis=1))
        # 5. Sum the correct predictions and calculate the average.
        pass
</code></pre>
      </div>

      <div class="nav">
        <a href="saving.html">&larr; Model Persistence</a>
        <a href="cnn.html">Next: Convolutional NN &rarr;</a>
      </div>

      <div class="attribution">
        <p>Original: <a href="https://zekcrates.quarto.pub/deep-learning-library/trainer.html">zekcrates/trainer</a></p>
      </div>
    </main>
  </div>
  <script src="copy.js"></script>
</body>
</html>
